{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mib as mb1\n",
    "import mib_v2_3_1 as mb\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planteamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar del rendimiento del motor de inferencia con problema pequeño y con tres eventon con distribuciones uniformes, donde su cardinalidad de los tres va de uno a cien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $A = \\{0, 2, ..., n-1\\}$\n",
    "\n",
    "- $B = \\{0, 2, ..., n-1\\}$\n",
    "\n",
    "- $C = \\{0, 2, ..., n-1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de descomposición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(ABC) = P(A)P(B|A)P(C|AB)$.\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$<img src=\"./P(ABC).jpg\" width=200/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(A)$, $P(B|A)$ y $P(C|AB)$ serán distribuciones uniformes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIB1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "timesM1 = []\n",
    "memoryM1 = []\n",
    "\n",
    "timesC1 = []\n",
    "memoryC1 = []\n",
    "\n",
    "for i in range(n):\n",
    "    Events = [x for x in range(i+1)]\n",
    "    # Varaibles\n",
    "    A = mb1.Var('A',Events)\n",
    "    B = mb1.Var('B',Events)\n",
    "    C = mb1.Var('C',Events)\n",
    "\n",
    "    dA = {}\n",
    "    dB_A = {}\n",
    "    dC_AB = []\n",
    "    value = 1 / (i+1)\n",
    "    for e in Events:\n",
    "        dA[e] = value\n",
    "        dB_A[e] = {}\n",
    "        for e1 in Events:\n",
    "            dB_A[e][e1] = value\n",
    "            tC_AB = []\n",
    "            for e2 in Events:\n",
    "                tC_AB.append(value)\n",
    "            dC_AB.append(tuple(tC_AB))\n",
    "    \n",
    "    PA=mb1.Distrib(name='P(A)',variable=[A],tabla=dA)\n",
    "    PB_A=mb1.DistribCond(name='P(B|A)',var=B,indep=[A],tabla=dB_A)\n",
    "    PC_AB=mb1.DistribCond('P(C|AB)',C,[A,B],dC_AB)\n",
    "    \n",
    "    PABC=mb1.JointDistrib(name='P(ABC)',variables=[A,B,C],descomp=[PA,PB_A,PC_AB])\n",
    "    Q_ABC=mb1.Question(joint=PABC)\n",
    "\n",
    "    #Inferencia de P(B)\n",
    "    tracemalloc.start()\n",
    "    \n",
    "    inicio = time.time()\n",
    "    PB = Q_ABC.query(searched=[B])\n",
    "    fin = time.time()\n",
    "    \n",
    "    memoria_actual, memoria_pico = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    tiempo_ejecucion = fin - inicio\n",
    "    \n",
    "    timesM1.append(tiempo_ejecucion)\n",
    "    memoryM1.append(memoria_pico)\n",
    "    \n",
    "    #Inferencia de P(A|BC)\n",
    "    tracemalloc.start()\n",
    "    \n",
    "    inicio = time.time()\n",
    "    PA_BC = Q_ABC.query(searched=[A], known=[B,C])\n",
    "    fin = time.time() \n",
    "    \n",
    "    memoria_actual, memoria_pico = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    tiempo_ejecucion = fin - inicio\n",
    "    \n",
    "    timesC1.append(tiempo_ejecucion)\n",
    "    memoryC1.append(memoria_pico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIB2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "timesM = []\n",
    "memoryM = []\n",
    "\n",
    "timesC = []\n",
    "memoryC = []\n",
    "\n",
    "for i in range(n):\n",
    "    Events = set([x for x in range(i+1)])\n",
    "    \n",
    "    # Generación de distribuciones de probabilidad (Distribuciones uniformes).\n",
    "    dA = {}\n",
    "    dB_A = {}\n",
    "    dC_AB = {}\n",
    "    value = 1 / (i+1)\n",
    "    for x in range(i+1):\n",
    "        dA[x] = value\n",
    "        dB_A[(x,)] = {}\n",
    "        for y in range(i+1):\n",
    "            dB_A[(x,)][y] = value\n",
    "            dC_AB[(x,y)] = {}\n",
    "            for z in range(i+1):\n",
    "                dC_AB[(x,y)][z] = value\n",
    "    \n",
    "    # Variables para el motor de inferencia.\n",
    "    A = mb.Var('A', Events)\n",
    "    PA = mb.Distrib(dA, (A.getName(),))\n",
    "    B = mb.Var('B', Events)\n",
    "    PB_A = mb.CondDistrib(dB_A, (B.getName(),), (A.getName()))\n",
    "    C = mb.Var('C', Events)\n",
    "    PC_AB = mb.CondDistrib(dC_AB, (C.getName(),), (A.getName(),B.getName()))\n",
    "    \n",
    "    # Probabilidad conjunta (Espesificación)\n",
    "    PABC = mb.Specification(set([A,B,C]), set([PA, PB_A, PC_AB]))\n",
    "\n",
    "    Q_ABC = mb.Question(PABC)\n",
    "    \n",
    "    # Inferencia de una marginal\n",
    "    tracemalloc.start()\n",
    "    \n",
    "    inicio = time.time()\n",
    "    PB = Q_ABC.DistributionQuery(set([B]))\n",
    "    fin = time.time()\n",
    "    \n",
    "    memoria_actual, memoria_pico = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    tiempo_ejecucion = fin - inicio\n",
    "    \n",
    "    timesM.append(tiempo_ejecucion)\n",
    "    memoryM.append(memoria_pico)\n",
    "    \n",
    "    # Inferencia de una condicional dada observaciones\n",
    "    tracemalloc.start()\n",
    "    \n",
    "    inicio = time.time()\n",
    "    PA_BC = Q_ABC.DistributionQuery(set([A]), set([B,C]))\n",
    "    fin = time.time()\n",
    "    \n",
    "    memoria_actual, memoria_pico = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    tiempo_ejecucion = fin - inicio\n",
    "    \n",
    "    timesC.append(tiempo_ejecucion)\n",
    "    memoryC.append(memoria_pico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiempos de inferencia para $P(B)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = [i+1 for i in range(n)]\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "# fig.set_size_inches(15,5)\n",
    "# MIB_1.0\n",
    "ax[0].plot(xn, timesM1, color='b',label = 'MIB_1.0')\n",
    "ax[0].set_title(\"Tiempo de inferencia para P(B) (MIB_1.0)\")\n",
    "ax[0].set_xlabel(\"n\")\n",
    "ax[0].set_ylabel(\"segundos\")\n",
    "\n",
    "# MIB_2.0\n",
    "ax[1].plot(xn, timesM, color='r',label = 'MIB_2.0')\n",
    "ax[1].set_title(\"Tiempo de inferencia para P(B) (MIB_2.0)\")\n",
    "ax[1].set_xlabel(\"n\")\n",
    "ax[1].set_ylabel(\"segundos\")\n",
    "\n",
    "# Mostrar las gráficas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# MIB_1.0\n",
    "ax.plot(xn, timesM1, color='b', label = 'MIB_1.0')\n",
    "\n",
    "# MIB_2.0\n",
    "ax.plot(xn, timesM, color='r',label = 'MIB_2.0')\n",
    "ax.set_title(\"Tiempo de inferencia para P(B)\")\n",
    "\n",
    "ax.set_xlabel(\"n\")\n",
    "ax.set_ylabel(\"segundos\")\n",
    "ax.legend(loc = 'upper left')\n",
    "\n",
    "# Mostrar las gráficas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiempos de inferencia para $P(C|AB)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = [i+1 for i in range(n)]\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "# fig.set_size_inches(15,5)\n",
    "# MIB_1.0\n",
    "ax[0].plot(xn, timesC1, color='b',label = 'MIB_1.0')\n",
    "ax[0].set_title(\"Tiempo de inferencia para P(C|AB) (MIB_1.0)\")\n",
    "ax[0].set_xlabel(\"n\")\n",
    "ax[0].set_ylabel(\"segundos\")\n",
    "\n",
    "# MIB_2.0\n",
    "ax[1].plot(xn, timesC, color='r',label = 'MIB_2.0')\n",
    "ax[1].set_title(\"Tiempo de inferencia para P(C|AB) (MIB_2.0)\")\n",
    "ax[1].set_xlabel(\"n\")\n",
    "ax[1].set_ylabel(\"segundos\")\n",
    "\n",
    "# Mostrar las gráficas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# MIB_1.0\n",
    "ax.plot(xn, timesC1, color='b', label = 'MIB_1.0')\n",
    "\n",
    "# MIB_2.0\n",
    "ax.plot(xn, timesC, color='r',label = 'MIB_2.0')\n",
    "ax.set_title(\"Tiempo de inferencia para P(B)\")\n",
    "\n",
    "ax.set_xlabel(\"n\")\n",
    "ax.set_ylabel(\"segundos\")\n",
    "ax.legend(loc = 'upper left')\n",
    "\n",
    "# Mostrar las gráficas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria para la inferencia de P(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "# fig.set_size_inches(15,5)\n",
    "# MIB_1.0\n",
    "ax[0].plot(xn, memoryM1, color='b',label = 'MIB_1.0')\n",
    "ax[0].set_title(\"Memoria para la inferencia para P(B) (MIB1.0)\")\n",
    "ax[0].set_xlabel(\"n\")\n",
    "ax[0].set_ylabel(\"MB\")\n",
    "\n",
    "# MIB_2.0\n",
    "ax[1].plot(xn, memoryM, color='r',label = 'MIB_2.0')\n",
    "ax[1].set_title(\"Memoria para la inferencia para P(B) (MIB2.0)\")\n",
    "ax[1].set_xlabel(\"n\")\n",
    "ax[1].set_ylabel(\"MB\")\n",
    "\n",
    "# Mostrar las gráficas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# MIB_1.0\n",
    "ax.plot(xn, memoryM1, color='b',label = 'MIB_1.0')\n",
    "\n",
    "# MIB_2.0\n",
    "ax.plot(xn, memoryM, color='r',label = 'MIB_2.0')\n",
    "ax.set_title(\"Memoria para la inferencia para P(B)\")\n",
    "\n",
    "ax.set_xlabel(\"n\")\n",
    "ax.set_ylabel(\"segundos\")\n",
    "ax.legend(loc = 'upper left')\n",
    "\n",
    "# Mostrar las gráficas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria para la inferencia de P(C|AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "# fig.set_size_inches(15,5)\n",
    "# MIB_1.0\n",
    "ax[0].plot(xn, memoryC1, color='b',label = 'MIB_1.0')\n",
    "ax[0].set_title(\"Memoria para la inferencia para P(C|AB) (MIB1.0)\")\n",
    "ax[0].set_xlabel(\"n\")\n",
    "ax[0].set_ylabel(\"MB\")\n",
    "\n",
    "# MIB_2.0\n",
    "ax[1].plot(xn, memoryC, color='r',label = 'MIB_2.0')\n",
    "ax[1].set_title(\"Memoria para la inferencia para P(C|AB) (MIB2.0)\")\n",
    "ax[1].set_xlabel(\"n\")\n",
    "ax[1].set_ylabel(\"MB\")\n",
    "\n",
    "# Mostrar las gráficas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# MIB_1.0\n",
    "ax.plot(xn, memoryC1, color='r',label = 'MIB_1.0')\n",
    "# MIB_2.0\n",
    "ax.plot(xn, memoryC, color='b',label = 'MIB_2.0')\n",
    "\n",
    "ax.set_title(\"Memoria para la inferencia para P(C|AB)\")\n",
    "\n",
    "ax.set_xlabel(\"n\")\n",
    "ax.set_ylabel(\"MB\")\n",
    "ax.legend(loc = 'upper left')\n",
    "\n",
    "# Mostrar las gráficas\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mib as mb1\n",
    "import mib_v2_3_1 as mb\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planteamineto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene un conjunto de correos, en los cuales se sabe si son spam o no, y se quiere saber si dada las palabras presentes en el correo el correo pertenece a spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $Spam := \\{0,1\\}$\n",
    "* $W_i = \\{0,1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P(Spam = 0) = 0.25$\n",
    "* $P(Spam = 1) = 0.75$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de descomposición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(Spam W_0 W_1 ... W_n ) = P(Spam)\\prod_i P(W_i|Spam)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada una de las $n$ formas de $P(W_i|Spam)$ debe ser espacificado. Para el conteo de la i-ésima palabra que aparesca spam y no spam \n",
    "\n",
    "* $P(W_i|Spam)$\n",
    "    * $P(W_i = true | Spam = false) = \\frac{1 + {n^i}_f}{|W_i| + n_f}$\n",
    "    * $P(W_i = true | Spam = true) = \\frac{1 + {n^i}_v}{|W_i| + n_t}$\n",
    "\n",
    "donde, ${n^i}_f$ es el número de apariciones de la i-ésima palabra en correos que no son spam y $n_f$ es el número total de correos que no son spam, ${n^i}_v$ es el número de apariciones de la i-ésima palabra en correos que son spam y $n_v$ es el número total de correos que son spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de distribuciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $P(Spam)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dSpam = {(0,):0.25, (1,):0.75}\n",
    "# Variables para el motor de inferencia.\n",
    "Spam = mb.Var('Spam',set([0,1]))\n",
    "PSpam = mb.Distrib(dSpam, (Spam.getName(),))\n",
    "PSpam.print_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variales $W_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = ['fortune','next','programming','money','you']\n",
    "W = {}\n",
    "events = set([0,1])\n",
    "\n",
    "for palabra in vocabulario:\n",
    "    W[palabra] = mb.Var(palabra, events)\n",
    "    print(f'W[{palabra}]: {W[palabra]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nif = [0,125,250,0,125] # Canitdad de veces que aparece una palabra en correos que no son spam.\n",
    "niv = [375,0,0,750,375] # Canitdad de veces que aparece una palabra en correos que son spam.\n",
    "\n",
    "nf = 250\n",
    "nv = 750\n",
    "\n",
    "PWi_Spam = {}\n",
    "\n",
    "i = 0\n",
    "for Wi in W:\n",
    "    tf = (1 + nif[i]) / (2 + nf)\n",
    "    tt = (1 + niv[i]) / (2 + nv)\n",
    "    dWi_Spam = {(0,): {(0,): 1 - tf, (1,):  tf},\n",
    "                (1,): {(0,): 1 - tt, (1,): tt}}\n",
    "    \n",
    "    PWi_Spam[Wi] = mb.CondDistrib(dWi_Spam, (W[Wi].getName(),), (Spam.getName(),))\n",
    "    i += 1\n",
    "for Wi in W:   \n",
    "    PWi_Spam[Wi].print_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de pregunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = set([W[i] for i in W] + [Spam])\n",
    "distribs = set([PWi_Spam[i] for i in W] + [PSpam])\n",
    "P_WiSpam = mb.Specification(vars, distribs)\n",
    "Q_WiSpam = mb.Question(P_WiSpam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()\n",
    "PSpam_wn = Q_WiSpam.DistributionQuery(set([Spam]), set([W[wi] for wi in W]))\n",
    "fin = time.time()\n",
    "tiempo_ejecucion = fin - inicio\n",
    "PSpam_wn.print_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempo_ejecucion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mib as mb1\n",
    "import mib_v2_3_1 as mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planteamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una compañía sabe que la contratación profesional de un candidato se efectúa luego de una entrevista, que se lleva a cabo en función de las calificaciones reportadas en el certificado del candidato y si éste tiene experiencia laboral o no. Generalmente, sólo se consideran los candidatos con calificaciones sobresalientes o regulares, y la entrevista arroja típicamente tres tipos de apreciación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compañía ha elaborado el siguiente modelo de contratación:\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$<img src=\"./MODELO_EMPRESA.jpg\" width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compañía ha recolectado datos históricos de los últimos 5 años sobre la evaluación de 500 candidatos y sabe que la proporción de candidatos con calificaciones regulares es del 30%, mientras que los candidatos con experiencia laboral representan el 60%. En la mejor condición, con calificaciones sobresalientes y experiencia laboral, los candidatos obtienen la más alta apreciación en la entrevista en un 80%, y la peor apreciación en un 2% de los casos. Estos porcentajes cambian respectivamente a 30% y 10% cuando las calificaciones no son las mejores, pero sí hay experiencia, y ambas son del 30% con calificaciones sobresalientes pero sin experiencia. En el peor caso, con calificaciones regulares y sin experiencia, los candidatos obtienen la mejor apreciación en la entrevista en un 10% y la peor en un 70%. Por último, se sabe que la tasa de candidatos rechazados es de un 10% cuando obtienen una apreciación favorable, un 60% cuando obtienen una apreciación regular, y un 99% cuando obtienen una apreciación desfavorable en la entrevista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $C := \\{0,1\\}$, donde C representa las calificaciones; 0 si son calificaciones reguales, 1 otro caso.\n",
    "* $E : = \\{0,1\\}$, donde E representa la experencia; \n",
    "* $N : = \\{0,1,2\\}$, donde  \n",
    "* $O : = \\{0,1\\}$, donde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de descomposición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(C E N O) = P(C)P(E)P(N|C E)P(N|O)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = mb.Var('E', set([0,1]))\n",
    "C = mb.Var('C', set([0,1]))\n",
    "O = mb.Var('O', set([0,1]))\n",
    "N = mb.Var('N', set([0,1,2]))\n",
    "\n",
    "dE = {(0,):0.4, (1,):0.6}\n",
    "dC = {(0,):0.3, (1,):0.7}\n",
    "dN_EC = {(0,0):{(0,):0.7, (1,):0.2, (2,):0.1},\n",
    "        (0,1):{(0,):0.3, (1,):0.4, (2,):0.3},\n",
    "        (1,0):{(0,):0.1, (1,):0.6, (2,):0.3},\n",
    "        (1,1):{(0,):0.02, (1,):0.18, (2,):0.8}}\n",
    "dO_N={(0,):{(0,):0.99, (1,):0.01},\n",
    "      (1,):{(0,):0.6, (1,):0.4},\n",
    "      (2,):{(0,):0.1, (1,):0.9}}\n",
    "\n",
    "P_E = mb.Distrib(dE, (E.getName(),))\n",
    "P_C = mb.Distrib(dC, (C.getName()))\n",
    "P_N_EC = mb.CondDistrib(dN_EC, (N.getName(),), (E.getName(), C.getName()))\n",
    "P_O_N = mb.CondDistrib(dO_N, (O.getName(),), (N.getName()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la especificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = set([E,C,N,O])\n",
    "P_ECNO = mb.Specification(vars,set([P_E,P_C,P_N_EC,P_O_N]))\n",
    "Q_P = mb.Question(P_ECNO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Cuál es su tasa de contratación \n",
    "#(i.e. cuál es la probabilidad de ser contratado). P(O)\n",
    "CONT = Q_P.Query(vars=(O,), vars_values = (1,))\n",
    "print(f'{round(CONT*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Cuantos candidatos ha contratado la compañía en los últimos 5 años. \n",
    "#X=P(O=0)*500.\n",
    "from math import floor\n",
    "\n",
    "X = floor(500*CONT)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Cuál es la tasa de apreciaciones favorables en la compañía.\n",
    "PN = Q_P.DistributionQuery(set(N))\n",
    "PN.print_table()\n",
    "FAV = Q_P.Query(vars=(N,), vars_values = (2,))\n",
    "print(f'{FAV*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Cuál es la tasa de apreciaciones regulares dado que se contrata a alguien. \n",
    "TAF = Q_P.Query(vars=(N,), indep=(O,), vars_values = (1,), indep_values=(0,))\n",
    "print(f'{TAF*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Cuál es la tasa de apreciaciones regulares dado que se contrata a alguien.\n",
    "TAF = Q_P.Query(vars=(N,), indep=(O,), vars_values = (0,), indep_values=(0,))\n",
    "print(f'{int(round(TAF*X,0))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Cuantos de los candidatos contratados obtuvieron una apreciación regular. \n",
    "#P(N=1|O=0)*X\n",
    "print(floor(TAF*X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Cómo se distribuye la contratación de candidatos en función de sus calificaciones. \n",
    "\n",
    "PO_C = Q_P.DistributionQuery(set([O]),set([C]))\n",
    "PO_C.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Cómo se distribuye la contratación de candidatos en función de su experiencia. \n",
    "\n",
    "PO_E = Q_P.DistributionQuery(set([O]),set([E]))\n",
    "PO_E.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Cuál es la probabilidad de que alguien con experiencia laboral tenga calificaciones sobresalientes. \n",
    "#P(C=0|E=0)\n",
    "ECS = Q_P.Query(vars=(C,), indep=(E,), vars_values = (0,), indep_values=(0,))\n",
    "print(f'{ECS*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Cuál es la distribución conjunta del personal contratado y \n",
    "#la apreciación de la entrevista.\n",
    "PON = Q_P.DistributionQuery(set([N,O]))\n",
    "PON.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpproc as tp\n",
    "from collections import Counter  #regresa un diccionario con conteos\n",
    "import glob\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import OrderedDict #diccionarios ordenados\n",
    "import numpy as np\n",
    "import mib as mb1\n",
    "import mib_v2_3_1 as mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planteamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema de autoria de textos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "- $A$ : Variable para los autores\n",
    "- $T$ : Variable para los tipos de textos\n",
    "- $W_I$ : Variable para las palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable $A$**\n",
    "\n",
    "- $A = $ Alfonso Reyes\n",
    "- $A = $ Esopo\n",
    "- $A = $ Fuentes\n",
    "- $A = $ García Márquez\n",
    "- $A = $ Gibran\n",
    "- $A = $ La Fontanie\n",
    "- $A = $ Onetti\n",
    "- $A = $ Quiroga\n",
    "- $A = $ Rulfo\n",
    "- $A = $ Saramago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable $T$**\n",
    "\n",
    "- $T = $ minicuento\n",
    "- $T = $ cuento\n",
    "- $T = $ fábula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable $W_i$**\n",
    "\n",
    "- $W_i = \\{0,1\\}$, donde cada $W_i$ representa una variable para una palabra y sus representaciones númericas son las siguientes:\n",
    "- $W_i = 0$ -> la palabra no esta.\n",
    "- $W_i = 1$ -> la palabra si esta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suponiendo un modelo de descomposición exacta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(A)P(T|A)\\displaystyle \\prod_{i=0}^{n} P(W_i|AT)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de datos para el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos = glob.glob('./Train/*/*')\n",
    "archivos,nombres = tp.carga_cuentos(archivos)\n",
    "df_train = tp.lee_cuentos(archivos)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos = glob.glob('./Test/*')\n",
    "archivos,nombres = tp.carga_cuentos(archivos)\n",
    "df_test = tp.lee_cuentos(archivos,test=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Frames de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_train.texto.str.cat(sep=' ').split()\n",
    "print(len(s))\n",
    "conteos=Counter(s)\n",
    "nuevo_vocabulario = list(set([palabra for palabra in s if conteos[palabra] <= 20 and conteos[palabra] >= 10 ]))\n",
    "print(len(nuevo_vocabulario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_T = df_train.copy()\n",
    "df_train_T['nuevo_texto'] = df_train_T.texto.str.split().\\\n",
    "    apply(lambda texto: [w for w in texto if w in nuevo_vocabulario]).\\\n",
    "    apply(lambda x : ' '.join(x))\n",
    "df_train_T['Conteos']=df_train_T.nuevo_texto.str.split().apply(Counter)\n",
    "\n",
    "\n",
    "df_train_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=df_test.texto.str.cat(sep=' ').split()\n",
    "print(len(s))\n",
    "conteos=Counter(s)\n",
    "nuevo_vocab = list(set([palabra for palabra in s if conteos[palabra] <= 20 and conteos[palabra] >= 10]))\n",
    "print(len(nuevo_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_T = df_test.copy()\n",
    "df_test_T['nuevo_texto']=df_test_T.texto.str.split().\\\n",
    "    apply(lambda texto: [w for w in texto if w in nuevo_vocab]).\\\n",
    "    apply(lambda x : ' '.join(x))\n",
    "df_test_T['nuevo_total']=df_test_T.nuevo_texto.str.split().apply(len)\n",
    "df_test_T['Conteos']=df_test_T.nuevo_texto.str.split().apply(Counter)\n",
    "\n",
    "\n",
    "df_test_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tamaño del vocabulario conjunto (total de palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = list(set(nuevo_vocabulario+nuevo_vocab))\n",
    "print(len(vocabulario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dict = OrderedDict(zip(vocabulario,range(len(vocabulario))))\n",
    "v = list(voc_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conteos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocurrencias de cada autor y conteos de ocurrencias y de número de autores\n",
    "oc_autor = Counter(df_train_T.autor)\n",
    "tot_oc_aut = np.sum(list(oc_autor.values()))\n",
    "tot_autores = len(oc_autor)\n",
    "\n",
    "# Ocurrencias de cada tipo y conteos de ocurrencias y de número de tipos\n",
    "oc_tipo = Counter(df_train_T.tipo)\n",
    "tot_oc_tipo = np.sum(list(oc_tipo.values()))\n",
    "tot_tipos = len(oc_tipo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autor\n",
    "autor_val = dict(zip(oc_autor.keys(),range(len(oc_autor.keys()))))\n",
    "val_autor = dict(zip(range(len(oc_autor.keys())),oc_autor.keys()))\n",
    "A = mb.Var('A',set(oc_autor.keys()))\n",
    "# Tipos\n",
    "tipo_val = dict(zip(oc_tipo.keys(),range(len(oc_tipo.keys()))))\n",
    "val_tipo = dict(zip(range(len(oc_tipo.keys())),oc_tipo.keys()))\n",
    "T = mb.Var('T',set(oc_tipo.keys()))\n",
    "\n",
    "# Palabras\n",
    "W = {}\n",
    "for w in voc_dict:    # vocabulario reducido\n",
    "    W[w] = mb.Var(w,set([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificación de parámetros (estadísticas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Descomposición exacta: $P(A)P(T|A)P(W|AT)$\n",
    "2. Calcular las estadísticas por cada distribución de la descomposición\n",
    "3. Para la variable Autor $P(A)$:\n",
    "    - 3.1 Contar el número total de ocurrencias de autores en Train: $n_a$.\n",
    "    - 3.2 Contar el número de ocurrencias de cada autor en Train: $n^i$.\n",
    "    - 3.3 Dividir este número entre el número total de ocurrencias de autores en Train: $\\displaystyle \\frac{n^i}{n_a}$.\n",
    "4. Para la variable Tipo $P(T|A)$:\n",
    "    - 4.1 Obtener el conjunto de autores (valores únicos) $a$; entradas a la Tabla.\n",
    "    - 4.2 Obtener el conjunto de tipos (valores únicos) $j$; estas son las salidas de la Tabla.\n",
    "    - 4.3 Calcular el producto cartesiano de las combinaciones posibles (a,j).\n",
    "    - 4.4 Contar el número de ocurrencias totales de cada $j$ por cada autor: $n^j_a$.\n",
    "    - 4.5 Dividir este número entre el número total de tipos por autor: $\\displaystyle \\frac{n^j_a}{\\sum n^j_a}$.\n",
    "    - 4.6 Aplicar la corrección de Laplace para evitar probabilidades en $0$.\n",
    "5. Para las variables W (palabras) $P(W|AT)$: **NOTA** se trata de calcular N Tablas, donde N es el tamaño del vocabulario.\n",
    "    - 5.1 Calcular el producto cartesiano de las combinaciones posibles (a,j); estas son las entradas a cada Tabla.\n",
    "    - 5.2 Por cada combinación, calcular la probabilidad de cada palabra del vocabulario, en función de su ocurrencia en esa combinación, aplicando la corrección de Laplace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribución P(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Contar el número total de ocurrencias de autores en Train: $n_a$: _tot_oc_aut_\n",
    "- Contar el número de ocurrencias de cada autor en Train: $n^i$: _oc_autor_ \n",
    "- Dividir este número entre el número total de ocurrencias de autores en Train: $\\displaystyle \\frac{n^i}{n_a}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_= []\n",
    "for autor in oc_autor:\n",
    "    n_.append(((autor,),oc_autor[autor]/tot_oc_aut))\n",
    "\n",
    "#Dicionario de valores de probabilidad\n",
    "dA = dict(n_)\n",
    "#Distribución de probabilidad\n",
    "PA = mb.Distrib(table = dA, columns=('A',))\n",
    "print(A.getValues())\n",
    "PA.print_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribución P(T|A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Obtener el conjunto de autores (valores únicos) $a$; entradas a la Tabla: _df_train.autor_\n",
    "   - Obtener el conjunto de tipos (valores únicos) $j$; estas son las salidas de la Tabla: _df_train.tipo_ \n",
    "   - Calcular el producto cartesiano de las combinaciones posibles (a,j): _pares_ta_\n",
    "   - Contar el número de ocurrencias totales de cada $j$ por cada autor: $n^j_a$: _conteo_pares_\n",
    "   - Dividir este número entre el número total de tipos por autor: $\\displaystyle \\frac{n^j_a}{\\sum n^j_a}$.\n",
    "   - Aplicar la corrección de Laplace para evitar probabilidades en $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocurrencias (conteos) de cada combinación (tipo,autor)\n",
    "conteo_pares = Counter(zip(df_train_T.autor,df_train_T.tipo))\n",
    "# print(conteo_pares)\n",
    "\n",
    "# Combinaciones (tipo,autor)\n",
    "autores = list(set(df_train_T.autor))\n",
    "tipos = list(set(df_train_T.tipo))\n",
    "\n",
    "dT_A = {}\n",
    "\n",
    "for autor, tipo in product(*[autores,tipos]):\n",
    "    par = (autor, tipo)\n",
    "    ak = (autor,)\n",
    "    \n",
    "    if ak in dT_A.keys():\n",
    "        if par in conteo_pares.keys():\n",
    "            dT_A[ak][(tipo,)] = conteo_pares[par]\n",
    "        else:\n",
    "            dT_A[ak][(tipo,)] = 0 \n",
    "    else:\n",
    "        if par in conteo_pares.keys():\n",
    "            dT_A[ak] = {(tipo,): conteo_pares[par]}\n",
    "        else:\n",
    "            dT_A[ak] = {(tipo,): 0}\n",
    "\n",
    "\n",
    "# Corrección de Laplace en el caso general\n",
    "# Se corrige la misma tabla que se senvía como argumento; no se crea una nueva.\n",
    "def Laplace_gral(tabla):\n",
    "    n = len(tabla[list(tabla.keys())[0]]) \n",
    "    for k in tabla.keys():\n",
    "        registro = tabla[k]\n",
    "        n_j = np.sum(list(registro.values()))\n",
    "        for i in registro.keys():\n",
    "            pb = (registro[i] + 1)/(n_j+n)\n",
    "            tabla[k][i]=pb\n",
    "    return\n",
    "\n",
    "Laplace_gral(dT_A)\n",
    "\n",
    "PT_A = mb.CondDistrib(set([T]), set([A]), dT_A, (T.getName(),), (A.getName(),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_A.print_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $P(W|AT)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Calcular el producto cartesiano de las combinaciones posibles (a,j); estas son las entradas a cada Tabla.\n",
    "   - Por cada combinación, calcular la probabilidad de cada palabra del vocabulario, en función de su ocurrencia en esa combinación, aplicando la corrección de Laplac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las palabras a tomar en cuenta son las del vocabulario.\n",
    "* Se deben codificar las combinaciones (a,t) en valores numéricos.\n",
    "* Por cada combinación (a,t):\n",
    "    - si existe una historia (nuevo_texto), entonces cada palabra de este cuento está presente, y el resto de las palabras del vocabulario están ausentes.\n",
    "    - si no hay historia, entonces ninguna palabra del vocabulario está presente --> Probabilidad 0 para todo el vocabulario.\n",
    "* Al aplicar la corrección de Laplace, evitamos que una combinación (a,t), que por ahora no tiene texto, se considere imposible, al asignarle una probabilidad mínima a cada palabra del vocabulario.\n",
    "* Para facilitar el \"conteo\" (presencia/ausencia) haremos un diccionario del vocabulario, incialmente en ceros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinaciones (tipo,autor)\n",
    "autores = list(set(df_train_T.autor))\n",
    "tipos = list(set(df_train_T.tipo))\n",
    "pares_ta = list(product(autores,tipos))\n",
    "\n",
    "# Conteos de palabras en nuevo_texto por pares (a,t) en el data frame de train\n",
    "conteo_w = dict(df_train_T.Conteos)\n",
    "pares_train = list(zip(df_train_T.autor,df_train_T.tipo))\n",
    "\n",
    "for i,k in enumerate(conteo_w.keys()):\n",
    "    conteo_w[k] = {pares_train[i] : dict(conteo_w[k])}\n",
    "    \n",
    "def check(palabra,pares_ta):\n",
    "    pw_ = {}\n",
    "    var = W[palabra]\n",
    "    \n",
    "    for par in pares_ta:\n",
    "        cw_1 = 0   # conteos de presencia \n",
    "        cw_0 = 0   # y ausencia en 0\n",
    "        it = 0     # total de pares (a,t) contabilizados\n",
    "        \n",
    "        for item in list(conteo_w.values()):  # checamos cada par (a,t) en el conjunto de train\n",
    "            # print(i,list(item.keys())[0], end=' ')\n",
    "            it += 1\n",
    "            if par in item: # checamos si el par (a,t) de entrada tiene correspondencia en Train\n",
    "                if palabra in list(item.values())[0]: #checamos si la palabra existe en el par (a,t) de Train\n",
    "                    cw_1 += 1\n",
    "                else:\n",
    "                    cw_0 += 1  #debemos contar también la no existencia por si hay igualdad\n",
    "        \n",
    "        if cw_0 == cw_1: # la palabra aparece por igual en todos los pares Train, o bien, no hay pares Train\n",
    "            pw_1 = 0.5   #corrección de Laplace que indica que la palabra puede o no estar por igual\n",
    "            pw_0 = 0.5\n",
    "            \n",
    "        else:\n",
    "            pw_1=(1+cw_1)/(len(var.getValues())+it) #corrección de Laplace en caso de que la palabra exista\n",
    "            pw_0 = 1-pw_1\n",
    "        \n",
    "        pw_[par] = {(0,): pw_0, (1,): pw_1}\n",
    "    pw_ = OrderedDict(sorted(pw_.items()))\n",
    "    return pw_\n",
    "        \n",
    "    \n",
    "PW_AT = {}\n",
    "for w in voc_dict:    # vocabulario reducido\n",
    "    t = check(w,pares_ta)\n",
    "    PW_AT[w] = mb.CondDistrib(set([W[w]]),set([A,T]), dict(t), (W[w].getName(),), (A.getName(), T.getName()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabra = list(PW_AT.keys())[0]\n",
    "print(palabra+':')\n",
    "PW_AT[list(PW_AT.keys())[0]].print_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl =  [A,T] + [W[w] for w in W] \n",
    "dl = [PA,PT_A] + [PW_AT[w] for w in PW_AT]\n",
    "vars_set = set(vl)\n",
    "dist_set = set(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregutas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATWi = mb.Specification(vars_set, dist_set)\n",
    "QW_AT = mb.Question(PATWi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ¿Quién escribió \"El caballo y el Lobo\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcont = df_test_T.loc[df_test['titulo'] == 'el caballo y el lobo', 'Conteos'].iloc[0]\n",
    "wit = []\n",
    "for w in dcont:\n",
    "    wit.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_wi = []\n",
    "for w in W:\n",
    "    if w in wit:\n",
    "        values_wi.append(1)\n",
    "    else:\n",
    "        values_wi.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $W = \\text{ todas las palabras}$\n",
    "- $Wt = \\text{ palabras que esten en el texto}$\n",
    "- $Wnt = \\text{ palabras que no esten en el texto}$\n",
    "- $W_i = 0 \\text{ si } w_i \\in wnt$\n",
    "- $W_i = 1 \\text{ si } w_i \\in wt$\n",
    "\n",
    "**Pregunta:**\n",
    "$ P(A | W_0, W_1, \\dots, W_n) $, donde se busca el valor más probable de $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA, VA, p = QW_AT.Query(vars=(A,), indep=tuple([W[w] for w in W]), values_indep=tuple(values_wi))\n",
    "VA, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wt = []\n",
    "Wt_v = []\n",
    "\n",
    "for w in wit:\n",
    "    Wt.append(W[w]),\n",
    "    Wt_v.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(W) + 2 - len(Wt_v) \n",
    "print('10^',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA, VA, p = QW_AT.Query(vars=(A,), indep=tuple(Wt), values_indep=tuple(Wt_v))\n",
    "VA, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de rendimiento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mib_v2_3 as mb2_3\n",
    "import mib_v2_3_thr as mb2_3tr\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "time_Q_TAW_nv = []\n",
    "\n",
    "for i in [10,11,12,13]:\n",
    "    time_Q_TAW = []\n",
    "\n",
    "    A = mb2_3.Var('A', set([j for j in range(10)]))\n",
    "    T = mb2_3.Var('T', set([0,1,2]))\n",
    "    W = [mb2_3.Var(j, set([0,1])) for j in range(i)]\n",
    "    \n",
    "    print(\"n_vocab: \",i)\n",
    "    dA = {}\n",
    "    for j in range(10):\n",
    "        dA[(j,)] = 1/10\n",
    "        \n",
    "    PA = mb2_3.Distrib(dA, ('A'))\n",
    "    \n",
    "    \n",
    "    dT_A = {}\n",
    "    for j in range(10):\n",
    "        dT_A[(j,)] = {}\n",
    "        for k in range(3):\n",
    "            dT_A[(j,)][(k,)] = 1/10\n",
    "        \n",
    "    PT_A = mb2_3.CondDistrib(dT_A, ('T',), ('A'))\n",
    "    \n",
    "    PW_AT = []\n",
    "    for wi in W:\n",
    "        dwi_TA = {}\n",
    "        for par in product(*[[0,1,2], [j for j in range(10)]]):\n",
    "            dwi_TA[par] = {}\n",
    "            for j in range(2):\n",
    "                dwi_TA[par][(j,)] = 0.5\n",
    "\n",
    "        PWi_AT = mb2_3.CondDistrib(dwi_TA, (wi.getName(),), ('T','A'))\n",
    "        PW_AT.append(PWi_AT)\n",
    "    \n",
    "    set_vars = set([A,T] + W)\n",
    "    set_descomp = set([PA, PT_A,] + PW_AT)\n",
    "    PATW = mb2_3.Specification(set_vars,set_descomp)\n",
    "    \n",
    "    QW_AT = mb2_3.Question(PATW)\n",
    "    \n",
    "    for j in range(i):\n",
    "        Wt = [W[k-1] for k in range(j+1)]\n",
    "        Wt_v = [1 for k in range(j+1)]\n",
    "        \n",
    "        inicio = time.time()\n",
    "        CA, VA, p = QW_AT.Query(vars=(A,), indep=tuple(Wt), values_indep=tuple(Wt_v))\n",
    "        fin = time.time()\n",
    "        print(\"n_w:\",j,\"-\",fin - inicio)\n",
    "        time_Q_TAW.append(fin - inicio)\n",
    "    \n",
    "    time_Q_TAW_nv.append(time_Q_TAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nc = 2\n",
    "nf = 2\n",
    "fig, axs = plt.subplots(nc, nf)\n",
    "fig.set_size_inches(10,8)\n",
    "f = 0\n",
    "c = 0\n",
    "for i,t in enumerate(time_Q_TAW_nv):\n",
    "    xn = [k+1 for k in range(len(t))]\n",
    "    axs[c,f].plot(xn, t)\n",
    "    axs[c,f].set_title(\"P(A|W0,...,Wr) con n = {n}\".format(n = len(t)))\n",
    "\n",
    "    axs[c,f].set_xlabel(\"r\")\n",
    "    axs[c,f].set_ylabel(\"segundos\")\n",
    "    \n",
    "    if f == nf - 1:\n",
    "        f = 0\n",
    "        if c == nc - 1:\n",
    "            c = 0\n",
    "        else:\n",
    "            c += 1\n",
    "    else:\n",
    "        f += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de $P(A|W_0,W_1,\\dots,W_n)$ y $P(A|W_0,W_1,\\dots,W_r,W_{r+1},\\dots,W_n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpproc as tp\n",
    "from collections import Counter  #regresa un diccionario con conteos\n",
    "import glob\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import OrderedDict #diccionarios ordenados\n",
    "import numpy as np\n",
    "import mib_v2_3 as mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos = glob.glob('./Train/*/*')\n",
    "archivos,nombres = tp.carga_cuentos(archivos)\n",
    "df_train = tp.lee_cuentos(archivos)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos = glob.glob('./Test/El Caballo y el Lobo.txt')\n",
    "archivos,nombres = tp.carga_cuentos(archivos)\n",
    "df_test = tp.lee_cuentos(archivos,test=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_train[df_train['autor'] == 'jean de la fontaine'].texto.str.cat(sep=' ').split()\n",
    "conteos = Counter(s)\n",
    "autor_vocabulario = set([palabra for palabra in s])\n",
    "print(len(autor_vocabulario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_test.texto.str.cat(sep=' ').split()\n",
    "conteos = Counter(s)\n",
    "vocab_test = set([palabra for palabra in s])\n",
    "print(len(vocab_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_T = df_train.copy()\n",
    "df_train_T['nuevo_texto'] = df_train_T.texto.str.split().\\\n",
    "    apply(lambda texto: [w for w in texto if w in autor_vocabulario]).\\\n",
    "    apply(lambda x : ' '.join(x))\n",
    "df_train_T['Conteos']=df_train_T.nuevo_texto.str.split().apply(Counter)\n",
    "df_train_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_T = df_test.copy()\n",
    "df_test_T['nuevo_texto']=df_test_T.texto.str.split().\\\n",
    "    apply(lambda texto: [w for w in texto if w in vocab_test]).\\\n",
    "    apply(lambda x : ' '.join(x))\n",
    "df_test_T['Conteos']=df_test_T.nuevo_texto.str.split().apply(Counter)\n",
    "\n",
    "\n",
    "df_test_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# Creación de variables\n",
    "\n",
    "# Vraible para autor\n",
    "# Ocurrencias de cada autor y conteos de ocurrencias y de número de autores\n",
    "oc_autor = Counter(df_train_T.autor)\n",
    "tot_oc_aut = np.sum(list(oc_autor.values()))\n",
    "tot_autores = len(oc_autor)\n",
    "A = mb.Var('A', set([autor for autor in oc_autor]))\n",
    "# Distribución P(A)\n",
    "n_= []\n",
    "for autor in oc_autor:\n",
    "    n_.append(((autor,),oc_autor[autor]/tot_oc_aut))\n",
    "\n",
    "# Dicionario de valores de probabilidad\n",
    "dA = dict(n_)\n",
    "# Distribución de probabilidad\n",
    "PA = mb.Distrib(vars=set([A]), table = dA, columns=('A',))\n",
    "print(A.getValues())\n",
    "PA.print_table()\n",
    "\n",
    "\n",
    "# Variable para tipos\n",
    "# Ocurrencias de cada tipo y conteos de ocurrencias y de número de tipos\n",
    "oc_tipo = Counter(df_train_T.tipo)\n",
    "tot_oc_tipo = np.sum(list(oc_tipo.values()))\n",
    "tot_tipos = len(oc_tipo)\n",
    "T = mb.Var('T', set([tipo for tipo in oc_tipo]))\n",
    "\n",
    "# Distribución P(T|A)\n",
    "\n",
    "# Ocurrencias (conteos) de cada combinación (tipo,autor)\n",
    "conteo_pares = Counter(zip(df_train_T.autor,df_train_T.tipo))\n",
    "# Combinaciones (tipo,autor)\n",
    "autores = list(set(df_train_T.autor))\n",
    "tipos = list(set(df_train_T.tipo))\n",
    "\n",
    "dT_A = {}\n",
    "\n",
    "for autor, tipo in product(*[autores,tipos]):\n",
    "    par = (autor, tipo)\n",
    "    ak = (autor,)\n",
    "    \n",
    "    if ak in dT_A.keys():\n",
    "        if par in conteo_pares.keys():\n",
    "            dT_A[ak][(tipo,)] = conteo_pares[par]\n",
    "        else:\n",
    "            dT_A[ak][(tipo,)] = 0 \n",
    "    else:\n",
    "        if par in conteo_pares.keys():\n",
    "            dT_A[ak] = {(tipo,): conteo_pares[par]}\n",
    "        else:\n",
    "            dT_A[ak] = {(tipo,): 0}\n",
    "            \n",
    "# Corrección de Laplace en el caso general\n",
    "# Se corrige la misma tabla que se senvía como argumento; no se crea una nueva.\n",
    "def Laplace_gral(tabla):\n",
    "    n = len(tabla[list(tabla.keys())[0]]) \n",
    "    for k in tabla.keys():\n",
    "        registro = tabla[k]\n",
    "        n_j = np.sum(list(registro.values()))\n",
    "        for i in registro.keys():\n",
    "            pb = (registro[i] + 1)/(n_j+n)\n",
    "            tabla[k][i]=pb\n",
    "\n",
    "Laplace_gral(dT_A)\n",
    "\n",
    "PT_A = mb.CondDistrib(set([T]), set([A]), dT_A, (T.getName(),), (A.getName(),))\n",
    "PT_A.print_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inter = vocab_test & autor_vocabulario\n",
    "vocab_dif = autor_vocabulario - vocab_test \n",
    "\n",
    "print(len(vocab_inter))\n",
    "print(len(vocab_dif))\n",
    "\n",
    "nuevo_vocab = vocab_inter.copy()\n",
    "\n",
    "ps_rn = []\n",
    "ps_n = []\n",
    "xn_p = []\n",
    "\n",
    "for i in range(20):\n",
    "    xn_p.append(len(nuevo_vocab))\n",
    "    df_train_T = df_train.copy()\n",
    "    df_train_T['nuevo_texto'] = df_train_T.texto.str.split().\\\n",
    "        apply(lambda texto: [w for w in texto if w in nuevo_vocab]).\\\n",
    "        apply(lambda x : ' '.join(x))\n",
    "    df_train_T['Conteos']=df_train_T.nuevo_texto.str.split().apply(Counter)\n",
    "    \n",
    "    # Palabras\n",
    "    W = {}\n",
    "    for w in nuevo_vocab:    # vocabulario reducido\n",
    "        W[w] = mb.Var(w,set([0,1]))\n",
    "    \n",
    "    # Combinaciones (tipo,autor)\n",
    "    autores = list(set(df_train_T.autor))\n",
    "    tipos = list(set(df_train_T.tipo))\n",
    "    pares_ta = list(product(autores,tipos))\n",
    "\n",
    "    # Conteos de palabras en nuevo_texto por pares (a,t) en el data frame de train\n",
    "    conteo_w = dict(df_train_T.Conteos)\n",
    "    pares_train = list(zip(df_train_T.autor,df_train_T.tipo))\n",
    "\n",
    "    for i,k in enumerate(conteo_w.keys()):\n",
    "        conteo_w[k] = {pares_train[i] : dict(conteo_w[k])}\n",
    "        \n",
    "    def check(palabra,pares_ta):\n",
    "        pw_ = {}\n",
    "        var = W[palabra]\n",
    "        \n",
    "        for par in pares_ta:\n",
    "            cw_1 = 0   # conteos de presencia \n",
    "            cw_0 = 0   # y ausencia en 0\n",
    "            it = 0     # total de pares (a,t) contabilizados\n",
    "            \n",
    "            for item in list(conteo_w.values()):  # checamos cada par (a,t) en el conjunto de train\n",
    "                # print(i,list(item.keys())[0], end=' ')\n",
    "                it += 1\n",
    "                if par in item: # checamos si el par (a,t) de entrada tiene correspondencia en Train\n",
    "                    if palabra in list(item.values())[0]: #checamos si la palabra existe en el par (a,t) de Train\n",
    "                        cw_1 += 1\n",
    "                    else:\n",
    "                        cw_0 += 1  #debemos contar también la no existencia por si hay igualdad\n",
    "            \n",
    "            if cw_0 == cw_1: # la palabra aparece por igual en todos los pares Train, o bien, no hay pares Train\n",
    "                pw_1 = 0.5   #corrección de Laplace que indica que la palabra puede o no estar por igual\n",
    "                pw_0 = 0.5\n",
    "                \n",
    "            else:\n",
    "                pw_1=(1+cw_1)/(len(var.getValues())+it) #corrección de Laplace en caso de que la palabra exista\n",
    "                pw_0 = 1-pw_1\n",
    "            \n",
    "            pw_[par] = {(0,): pw_0, (1,): pw_1}\n",
    "        pw_ = OrderedDict(sorted(pw_.items()))\n",
    "        return pw_\n",
    "            \n",
    "        \n",
    "    PW_AT = {}\n",
    "    for w in nuevo_vocab:    # vocabulario reducido\n",
    "        t = check(w,pares_ta)\n",
    "        PW_AT[w] = mb.CondDistrib(set([W[w]]),set([A,T]), dict(t), (W[w].getName(),), (A.getName(), T.getName()))\n",
    "        \n",
    "    vars_set = set([A,T] + [W[w] for w in W]) \n",
    "    descomp_set = set([PA, PT_A] + [PW_AT[w] for w in W])\n",
    "    PATW = mb.Specification(vars_set, descomp_set)\n",
    "    \n",
    "    Q_PATW = mb.Question(PATW)\n",
    "    \n",
    "    values_wi = []\n",
    "    for w in W:\n",
    "        if w in vocab_inter:\n",
    "            values_wi.append(1)\n",
    "        else:\n",
    "            values_wi.append(0)\n",
    "    \n",
    "    p = Q_PATW.Query(vars=tuple([A]), indep=tuple([W[w] for w in W]), values_var = tuple(['jean de la fontaine']),values_indep = values_wi)\n",
    "    ps_n.append(p)\n",
    "    \n",
    "    indep_wi = tuple([W[w] for w in vocab_inter])\n",
    "    values_iwi = tuple([1 for w in indep_wi])\n",
    "    p = Q_PATW.Query(vars=tuple([A]), indep = indep_wi, values_var = tuple(['jean de la fontaine']),values_indep = values_iwi)\n",
    "    ps_rn.append(p)\n",
    "    \n",
    "    nuevo_vocab.add(vocab_dif.pop())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches(15,5)\n",
    "\n",
    "axs[0].plot(xn_p, ps_n, color = 'r',label = \"Como decisión\")\n",
    "axs[0].set_title(\"P(A|W0,W1,Wr,...,Wn)\")\n",
    "axs[0].set_xlabel(\"n\")\n",
    "axs[0].set_ylabel(\"P\")\n",
    "\n",
    "\n",
    "axs[1].plot([n-20 for n in xn_p], ps_rn, color = 'b', label = \"Con división\")\n",
    "axs[1].set_title(\"P(A|W0,W1,Wr)\")\n",
    "axs[1].set_xlabel(\"n - r\")\n",
    "axs[1].set_ylabel(\"P\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
